# PrediÃ§Ã£o de Diabetes com Modelos Supervisionados

Este projeto implementa e compara diferentes abordagens supervisionadas para prediÃ§Ã£o do risco de diabetes mellitus, com base em dados clÃ­nicos simples. SÃ£o utilizadas abordagens estatÃ­sticas (regressÃ£o logÃ­stica) e computacionais (Perceptron, MLP), com anÃ¡lise completa de desempenho, calibraÃ§Ã£o e viabilidade interpretativa.

## ğŸ” Objetivo

Avaliar o desempenho e a interpretabilidade de diferentes modelos supervisionados aplicados ao conjunto de dados de diabetes do repositÃ³rio UCI. As abordagens incluem:

- **RegressÃ£o LogÃ­stica (EstatÃ­stica ClÃ¡ssica)**  
- **RegressÃ£o LogÃ­stica (ML)**  
- **Perceptron**  
- **Multilayer Perceptron (MLP)**  

## ğŸ—‚ï¸ OrganizaÃ§Ã£o dos Arquivos

| Arquivo                         | DescriÃ§Ã£o                                                                 |
|--------------------------------|---------------------------------------------------------------------------|
| `regressao_logistica.ipynb`    | Abordagem estatÃ­stica clÃ¡ssica com ajuste linear, splines e calibraÃ§Ã£o.  |
| `perceptron_mlp_cnn.ipynb`     | Abordagem computacional com Perceptron e MLP implementados em Keras.     |
| `multilayer_perceptron.ipynb`  | Treinamento e avaliaÃ§Ã£o detalhada de uma MLP com duas camadas ocultas.   |
| `mlp.ipynb`                     | Script alternativo com foco na arquitetura e visualizaÃ§Ã£o de mÃ©tricas.   |
| `aed.ipynb`                     | AnÃ¡lise exploratÃ³ria dos dados (limpeza, transformaÃ§Ã£o e visualizaÃ§Ã£o).  |
| `Supervised_Learning_All_Days.pdf` | Material teÃ³rico de apoio (ML, VC-dim, otimizaÃ§Ã£o, teoria dos modelos). |

## ğŸ“Š Base de Dados

Conjunto `Pima Indians Diabetes` da UCI, com 768 observaÃ§Ãµes e 9 variÃ¡veis clÃ­nicas.  
ApÃ³s limpeza e exclusÃ£o de valores impossÃ­veis (ex: IMC = 0), foram mantidas 392 observaÃ§Ãµes.

### Preditores utilizados:

- **Glucose** â€“ Glicemia de jejum  
- **BMI** â€“ Ãndice de Massa Corporal  
- **Age** â€“ Idade  
- **Pregnancies** â€“ NÃºmero de gestaÃ§Ãµes  

Estes foram escolhidos com base em significÃ¢ncia estatÃ­stica, disponibilidade prÃ¡tica e coerÃªncia clÃ­nica.

## âš™ï¸ Modelos Implementados

### ğŸ”¹ RegressÃ£o LogÃ­stica (EstatÃ­stica)
- Implementada em R com `glm()` e `rms::lrm()`
- CalibraÃ§Ã£o via Hosmerâ€“Lemeshow e `bootstrap`
- Curva de calibraÃ§Ã£o gerada para anÃ¡lise de ajuste
- Interpretabilidade direta por coeficientes

### ğŸ”¹ Multilayer Perceptron (MLP)
- Implementado com Keras/TensorFlow
- Arquitetura: [8 entradas] â†’ [6] â†’ [3] â†’ [2 saÃ­das, Softmax]
- OtimizaÃ§Ã£o com `gradient descent` (batch, 1.500 Ã©pocas)
- AtivaÃ§Ã£o ReLU nas camadas ocultas

### ğŸ”¹ Perceptron
- Classificador linear simples
- Acompanhado de estudo teÃ³rico e histÃ³rico

## ğŸ“ˆ AvaliaÃ§Ã£o de Desempenho

| MÃ©trica           | Linear (ValidaÃ§Ã£o) | MLP (ValidaÃ§Ã£o) |
|------------------|--------------------|------------------|
| AcurÃ¡cia          | 0,831              | 0,831            |
| AUC               | 0,863              | 0,869            |
| Sensibilidade     | 0,872              | 0,897            |
| Especificidade    | 0,750              | 0,700            |
| Balanced Accuracy | 0,811              | 0,799            |

- O modelo linear apresentou desempenho comparÃ¡vel ao MLP, com vantagem interpretativa e menor risco de sobreajuste.

## ğŸ“Œ ConclusÃµes

- A **RegressÃ£o LogÃ­stica Linear** com recalibraÃ§Ã£o demonstrou excelente desempenho preditivo e interpretabilidade clÃ­nica.
- O modelo **MLP** apresentou leve vantagem em AUC, mas com maior custo computacional e menor especificidade.
- O modelo linear Ã© preferÃ­vel para triagem populacional, especialmente em cenÃ¡rios com recursos computacionais limitados.

## ğŸ“š ReferÃªncias

O material teÃ³rico e metodolÃ³gico estÃ¡ documentado no PDF [`Supervised_Learning_All_Days.pdf`](Supervised_Learning_All_Days.pdf), incluindo:

- HistÃ³ria e limites do Perceptron
- Teoria da VC-dimensÃ£o e generalizaÃ§Ã£o
- OtimizaÃ§Ã£o com descida de gradiente
- ComparaÃ§Ã£o entre modelos estatÃ­sticos e computacionais

## ğŸ‘¨â€ğŸ”¬ Autoria

Projeto desenvolvido por Pedro Brom, George FabrÃ­cio, Charles Santos e Alexandro de Paula  
Programa de PÃ³s-GraduaÃ§Ã£o em InformÃ¡tica (PPGI) â€“ Universidade de BrasÃ­lia

---

