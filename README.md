# Predi√ß√£o de Diabetes com Modelos Supervisionados

Este projeto implementa e compara diferentes abordagens supervisionadas para predi√ß√£o do risco de diabetes mellitus, com base em dados cl√≠nicos simples. S√£o utilizadas abordagens estat√≠sticas (regress√£o log√≠stica) e computacionais (Perceptron, MLP), com an√°lise completa de desempenho, calibra√ß√£o e viabilidade interpretativa.

## üîç Objetivo

Avaliar o desempenho e a interpretabilidade de diferentes modelos supervisionados aplicados ao conjunto de dados de diabetes do reposit√≥rio UCI. As abordagens incluem:

- **Regress√£o Log√≠stica (Estat√≠stica Cl√°ssica)**  
- **Regress√£o Log√≠stica (ML)**  
- **Perceptron**  
- **Multilayer Perceptron (MLP)**  

## üóÇÔ∏è Organiza√ß√£o dos Arquivos

| Arquivo                         | Descri√ß√£o                                                                 |
|--------------------------------|---------------------------------------------------------------------------|
| `regressao_logistica.ipynb`    | Abordagem estat√≠stica cl√°ssica com ajuste linear, splines e calibra√ß√£o.  |
| `perceptron_mlp_cnn.ipynb`     | Abordagem computacional com Perceptron e MLP implementados em Keras.     |
| `multilayer_perceptron.ipynb`  | Treinamento e avalia√ß√£o detalhada de uma MLP com duas camadas ocultas.   |
| `mlp.ipynb`                     | Script alternativo com foco na arquitetura e visualiza√ß√£o de m√©tricas.   |
| `aed.ipynb`                     | An√°lise explorat√≥ria dos dados (limpeza, transforma√ß√£o e visualiza√ß√£o).  |
| `Supervised_Learning_All_Days.pdf` | Material te√≥rico de apoio (ML, VC-dim, otimiza√ß√£o, teoria dos modelos). |

## üìä Base de Dados

Conjunto `Pima Indians Diabetes` da UCI, com 768 observa√ß√µes e 9 vari√°veis cl√≠nicas.  
Ap√≥s limpeza e exclus√£o de valores imposs√≠veis (ex: IMC = 0), foram mantidas 392 observa√ß√µes.

### Preditores utilizados:

- **Glucose** ‚Äì Glicemia de jejum  
- **BMI** ‚Äì √çndice de Massa Corporal  
- **Age** ‚Äì Idade  
- **Pregnancies** ‚Äì N√∫mero de gesta√ß√µes  

Estes foram escolhidos com base em signific√¢ncia estat√≠stica, disponibilidade pr√°tica e coer√™ncia cl√≠nica.

## ‚öôÔ∏è Modelos Implementados

### üîπ Regress√£o Log√≠stica (Estat√≠stica)
- Implementada em R com `glm()` e `rms::lrm()`
- Calibra√ß√£o via Hosmer‚ÄìLemeshow e `bootstrap`
- Curva de calibra√ß√£o gerada para an√°lise de ajuste
- Interpretabilidade direta por coeficientes

### üîπ Multilayer Perceptron (MLP)
- Implementado com Keras/TensorFlow
- Arquitetura: [8 entradas] ‚Üí [6] ‚Üí [3] ‚Üí [2 sa√≠das, Softmax]
- Otimiza√ß√£o com `gradient descent` (batch, 1.500 √©pocas)
- Ativa√ß√£o ReLU nas camadas ocultas

### üîπ Perceptron
- Classificador linear simples
- Acompanhado de estudo te√≥rico e hist√≥rico

## üìà Avalia√ß√£o de Desempenho

| M√©trica           | Linear (Valida√ß√£o) | MLP (Valida√ß√£o) |
|------------------|--------------------|------------------|
| Acur√°cia          | 0,831              | 0,831            |
| AUC               | 0,863              | 0,869            |
| Sensibilidade     | 0,872              | 0,897            |
| Especificidade    | 0,750              | 0,700            |
| Balanced Accuracy | 0,811              | 0,799            |

- O modelo linear apresentou desempenho compar√°vel ao MLP, com vantagem interpretativa e menor risco de sobreajuste.

## üìå Conclus√µes

- A **Regress√£o Log√≠stica Linear** com recalibra√ß√£o demonstrou excelente desempenho preditivo e interpretabilidade cl√≠nica.
- O modelo **MLP** apresentou leve vantagem em AUC, mas com maior custo computacional e menor especificidade.
- O modelo linear √© prefer√≠vel para triagem populacional, especialmente em cen√°rios com recursos computacionais limitados.

## üìö Refer√™ncias

O material te√≥rico e metodol√≥gico est√° documentado no PDF [`Supervised_Learning_All_Days.pdf`](Supervised_Learning_All_Days.pdf), incluindo:

- Hist√≥ria e limites do Perceptron
- Teoria da VC-dimens√£o e generaliza√ß√£o
- Otimiza√ß√£o com descida de gradiente
- Compara√ß√£o entre modelos estat√≠sticos e computacionais

## üë®‚Äçüî¨ Autoria

Projeto desenvolvido por [Pedro Brom](https://github.com/pcbrom), George Fabr√≠cio, [Charles Santos](https://github.com/thyarles) e Alexandro de Paula  
Programa de P√≥s-Gradua√ß√£o em Inform√°tica (PPGI) ‚Äì Universidade de Bras√≠lia

---

