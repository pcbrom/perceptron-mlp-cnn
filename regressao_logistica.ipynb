{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rIO99_vW3L42",
    "outputId": "cc7c81ac-032a-45f2-c659-1f1346869bfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Instala pacotes necessários em silêncio\n",
    "%pip install -q imbalanced-learn pandas scikit-learn seaborn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7npumyNsPQkJ"
   },
   "outputs": [],
   "source": [
    "# Importação das Bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from imblearn.over_sampling import SMOTE, ADASYN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9kFEAxOjQO2W"
   },
   "source": [
    "**Análise Exploratória dos dados **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "eQnzGt689ODH",
    "outputId": "af11d5fe-2335-439a-8a3d-997a1d9c7433"
   },
   "outputs": [],
   "source": [
    "# Configurações de visualização\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "# Carregamento dos dados\n",
    "url = \"https://raw.githubusercontent.com/pcbrom/perceptron-mlp-cnn/refs/heads/main/data/diabetes.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print(\"Dimensão do dataset:\", df.shape)\n",
    "print(\"\\nPrimeiras linhas do dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nInformações gerais:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nEstatísticas descritivas:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\nValores ausentes:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Algumas colunas usam 0 como valor ausente\n",
    "zero_cols = [\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"]\n",
    "print(\"\\nValores Nulos Por Colunas:\")\n",
    "print((df[zero_cols] == 0).sum())\n",
    "\n",
    "# Histograma das variáveis\n",
    "df.hist(bins=30, figsize=(15, 10), color=\"steelblue\")\n",
    "plt.suptitle(\"Distribuição das Variáveis\")\n",
    "plt.show()\n",
    "\n",
    "# Boxplots para identificar outliers\n",
    "for col in df.columns[:-1]:\n",
    "    sns.boxplot(x=df[col])\n",
    "    plt.title(f\"Boxplot de {col}\")\n",
    "    plt.show()\n",
    "\n",
    "# Matriz de correlação\n",
    "corr_matrix = df.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Matriz de Correlação\")\n",
    "plt.show()\n",
    "\n",
    "# Distribuição das classes\n",
    "sns.countplot(x=\"Outcome\", data=df, palette=\"viridis\")\n",
    "plt.title(\"Distribuição das Classes (Outcome)\")\n",
    "plt.xticks([0, 1], [\"Não Diabético\", \"Diabético\"])\n",
    "plt.xlabel(\"Classe\")\n",
    "plt.ylabel(\"Frequência\")\n",
    "plt.show()\n",
    "\n",
    "# Comparação entre classes para variáveis principais\n",
    "features_to_plot = [\"Glucose\", \"BMI\", \"Age\"]\n",
    "for feature in features_to_plot:\n",
    "    sns.histplot(data=df, x=feature, hue=\"Outcome\", kde=True, element=\"step\")\n",
    "    plt.title(f\"Distribuição de {feature} por Classe\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-KbJZk9UoXs"
   },
   "source": [
    "**Regressão Logística Sem a Utilização de SMOTE e ADASYN**\n",
    "\n",
    "SMOTE e ADASYN são métodos de oversampling supervisionado usados antes do treinamento do modelo para balancear datasets desbalanceados.\n",
    "\n",
    "SMOTE (Synthetic Minority Over-sampling Technique) gera novas amostras sintéticas da classe minoritária.As novas amostras são criadas interpolando entre amostras reais e seus vizinhos mais próximos.Isso evita simplesmente duplicar dados existentes, o que poderia causar overfitting. No dataset em quentão a classe diabéticos é menor que a classe não diabéticos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-kNHqE3bTLw"
   },
   "source": [
    "**Regressão Logística SEM Utilização de SMOTE e ADASYN. Com Diversos Limiares**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6WQaiHTkbFqs",
    "outputId": "da2539a8-dbd8-45f5-af66-edc91e3c4287"
   },
   "outputs": [],
   "source": [
    "# Substitui zeros por NaN nas colunas relevantes\n",
    "cols_with_zeros = [\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"]\n",
    "df[cols_with_zeros] = df[cols_with_zeros].replace(0, np.nan)\n",
    "\n",
    "# Imputação dos valores ausentes com a mediana\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "df[cols_with_zeros] = imputer.fit_transform(df[cols_with_zeros])\n",
    "\n",
    "# Separação de features e target\n",
    "X = df.drop(\"Outcome\", axis=1)\n",
    "y = df[\"Outcome\"]\n",
    "\n",
    "# Padronização dos dados\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Divisão em treino e teste (estratificada)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Treinamento do modelo de regressão logística\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Probabilidades previstas\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Avaliação para múltiplos limiares\n",
    "thresholds = np.arange(0.1, 0.91, 0.05)\n",
    "resultados = []\n",
    "\n",
    "for thresh in thresholds:\n",
    "    y_pred_thresh = (y_proba >= thresh).astype(int)\n",
    "    precision = precision_score(y_test, y_pred_thresh)\n",
    "    recall = recall_score(y_test, y_pred_thresh)\n",
    "    f1 = f1_score(y_test, y_pred_thresh)\n",
    "    resultados.append((thresh, precision, recall, f1))\n",
    "\n",
    "df_limiar = pd.DataFrame(\n",
    "    resultados, columns=[\"Limiar\", \"Precisão\", \"Recall\", \"F1-Score\"]\n",
    ")\n",
    "print(\"\\nAvaliação por múltiplos limiares:\")\n",
    "print(df_limiar)\n",
    "\n",
    "# Seleciona o melhor limiar com base no F1-score\n",
    "melhor_limiar = df_limiar.loc[df_limiar[\"F1-Score\"].idxmax(), \"Limiar\"]\n",
    "print(f\"\\nMelhor limiar com base no F1-score: {melhor_limiar:.2f}\")\n",
    "\n",
    "# Predição final com limiar otimizado\n",
    "y_pred_final = (y_proba >= melhor_limiar).astype(int)\n",
    "\n",
    "print(\"\\nAvaliação Final com Limiar Otimizado:\")\n",
    "print(\"Acurácia:\", accuracy_score(y_test, y_pred_final))\n",
    "print(\"Precisão:\", precision_score(y_test, y_pred_final))\n",
    "print(\"Revocação (Recall):\", recall_score(y_test, y_pred_final))\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred_final))\n",
    "\n",
    "# Plot das métricas por limiar\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_limiar[\"Limiar\"], df_limiar[\"Precisão\"], label=\"Precisão\")\n",
    "plt.plot(df_limiar[\"Limiar\"], df_limiar[\"Recall\"], label=\"Recall\")\n",
    "plt.plot(df_limiar[\"Limiar\"], df_limiar[\"F1-Score\"], label=\"F1-Score\", linewidth=2)\n",
    "plt.xlabel(\"Limiar\")\n",
    "plt.ylabel(\"Métrica\")\n",
    "plt.title(\"Avaliação de Métricas por Limiar\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Curva ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color=\"darkorange\", lw=2, label=f\"Curva ROC (AUC = {roc_auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], color=\"gray\", linestyle=\"--\")\n",
    "plt.xlabel(\"Taxa de Falsos Positivos (FPR)\")\n",
    "plt.ylabel(\"Taxa de Verdadeiros Positivos (TPR)\")\n",
    "plt.title(\"Curva ROC - Regressão Logística\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdYP3cN-U70s"
   },
   "source": [
    "**Regressão Logística Com a Utilização de SMOTE e Diversos Limiares**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "aMs_799u3RCi",
    "outputId": "7511991c-72e5-4979-dbe5-1ef9fb2b7722"
   },
   "outputs": [],
   "source": [
    "# Imputação novamente (já foi feita antes, pode ser removida)\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "df[cols_with_zeros] = imputer.fit_transform(df[cols_with_zeros])\n",
    "\n",
    "# Separação de features e target\n",
    "X = df.drop(\"Outcome\", axis=1)\n",
    "y = df[\"Outcome\"]\n",
    "\n",
    "# Padronização dos dados\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Divisão em treino e teste (estratificada)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# SMOTE para balanceamento da base de treino\n",
    "smote = SMOTE(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# ADASYN para balanceamento da base de treino\n",
    "adasyn = ADASYN(random_state=42)\n",
    "X_adasyn, y_adasyn = adasyn.fit_resample(X_train, y_train)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Modelo com SMOTE\n",
    "model.fit(X_smote, y_smote)\n",
    "\n",
    "# Probabilidades previstas\n",
    "y_proba_smote = model.predict_proba(X_test)[:, 1]\n",
    "limiar = 0.9\n",
    "y_pred_smote = (y_proba_smote >= limiar).astype(int)\n",
    "\n",
    "print(\"\\nAvaliação com SMOTE:\")\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test, y_pred_smote, target_names=[\"Não Diabético\", \"Diabético\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Avaliação multi-limiar para modelo com SMOTE\n",
    "thresholds = np.arange(0.1, 0.91, 0.05)\n",
    "resultados = []\n",
    "\n",
    "for thresh in thresholds:\n",
    "    y_pred_thresh = (y_proba_smote >= thresh).astype(int)\n",
    "    precision = precision_score(y_test, y_pred_thresh)\n",
    "    recall = recall_score(y_test, y_pred_thresh)\n",
    "    f1 = f1_score(y_test, y_pred_thresh)\n",
    "    resultados.append((thresh, precision, recall, f1))\n",
    "\n",
    "# DataFrame com métricas por limiar\n",
    "df_limiar = pd.DataFrame(\n",
    "    resultados, columns=[\"Limiar\", \"Precisão\", \"Recall\", \"F1-Score\"]\n",
    ")\n",
    "print(\"\\nAvaliação por múltiplos limiares (SMOTE):\")\n",
    "print(df_limiar)\n",
    "\n",
    "# Plot das métricas por limiar\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_limiar[\"Limiar\"], df_limiar[\"Precisão\"], label=\"Precisão\")\n",
    "plt.plot(df_limiar[\"Limiar\"], df_limiar[\"Recall\"], label=\"Recall\")\n",
    "plt.plot(df_limiar[\"Limiar\"], df_limiar[\"F1-Score\"], label=\"F1-Score\", linewidth=2)\n",
    "plt.xlabel(\"Limiar\")\n",
    "plt.ylabel(\"Métrica\")\n",
    "plt.title(\"Avaliação de Métricas por Limiar (SMOTE)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Curva ROC para SMOTE\n",
    "fpr_smote, tpr_smote, _ = roc_curve(y_test, y_proba_smote)\n",
    "auc_smote = auc(fpr_smote, tpr_smote)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(\n",
    "    fpr_smote, tpr_smote, color=\"blue\", lw=2, label=f\"SMOTE (AUC = {auc_smote:.2f})\"\n",
    ")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\", lw=1)\n",
    "plt.xlabel(\"Taxa de Falsos Positivos (FPR)\")\n",
    "plt.ylabel(\"Taxa de Verdadeiros Positivos (TPR)\")\n",
    "plt.title(\"Curva ROC - Regressão Logística com SMOTE\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B2BUCcAnaoLJ"
   },
   "source": [
    "**Regressão Logística Com a Utilização de ADASYN e Diversos Limiares**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DN3vkTu9Yf8C",
    "outputId": "2982d050-0f92-4114-ddfe-d518c81a0192"
   },
   "outputs": [],
   "source": [
    "# Modelo com ADASYN\n",
    "model.fit(X_adasyn, y_adasyn)\n",
    "y_proba_adasyn = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Avaliação multi-limiar automática\n",
    "thresholds = np.arange(0.1, 0.91, 0.05)\n",
    "resultados_adasyn = []\n",
    "\n",
    "for thresh in thresholds:\n",
    "    y_pred_thresh = (y_proba_adasyn >= thresh).astype(int)\n",
    "    precision = precision_score(y_test, y_pred_thresh)\n",
    "    recall = recall_score(y_test, y_pred_thresh)\n",
    "    f1 = f1_score(y_test, y_pred_thresh)\n",
    "    resultados_adasyn.append((thresh, precision, recall, f1))\n",
    "\n",
    "# DataFrame de resultados\n",
    "df_adasyn = pd.DataFrame(\n",
    "    resultados_adasyn, columns=[\"Limiar\", \"Precisão\", \"Recall\", \"F1-Score\"]\n",
    ")\n",
    "print(\"\\nAvaliação por múltiplos limiares (ADASYN):\")\n",
    "print(df_adasyn)\n",
    "\n",
    "# Limiar ótimo com base no F1-score\n",
    "melhor_limiar_adasyn = df_adasyn.loc[df_adasyn[\"F1-Score\"].idxmax(), \"Limiar\"]\n",
    "print(f\"\\nMelhor limiar para ADASYN (F1-score): {melhor_limiar_adasyn:.2f}\")\n",
    "\n",
    "# Previsão com limiar ótimo\n",
    "y_pred_adasyn = (y_proba_adasyn >= melhor_limiar_adasyn).astype(int)\n",
    "\n",
    "# Relatório final\n",
    "print(\"\\nAvaliação final com ADASYN (limiar otimizado):\")\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test, y_pred_adasyn, target_names=[\"Não Diabético\", \"Diabético\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot das métricas por limiar\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_adasyn[\"Limiar\"], df_adasyn[\"Precisão\"], label=\"Precisão\")\n",
    "plt.plot(df_adasyn[\"Limiar\"], df_adasyn[\"Recall\"], label=\"Recall\")\n",
    "plt.plot(df_adasyn[\"Limiar\"], df_adasyn[\"F1-Score\"], label=\"F1-Score\", linewidth=2)\n",
    "plt.xlabel(\"Limiar\")\n",
    "plt.ylabel(\"Métrica\")\n",
    "plt.title(\"Avaliação de Métricas por Limiar (ADASYN)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Curva ROC para ADASYN\n",
    "fpr_adasyn, tpr_adasyn, _ = roc_curve(y_test, y_proba_adasyn)\n",
    "auc_adasyn = auc(fpr_adasyn, tpr_adasyn)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(\n",
    "    fpr_adasyn,\n",
    "    tpr_adasyn,\n",
    "    color=\"darkorange\",\n",
    "    lw=2,\n",
    "    label=f\"ADASYN (AUC = {auc_adasyn:.2f})\",\n",
    ")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\", lw=1)\n",
    "plt.xlabel(\"Taxa de Falsos Positivos (FPR)\")\n",
    "plt.ylabel(\"Taxa de Verdadeiros Positivos (TPR)\")\n",
    "plt.title(\"Curva ROC - Regressão Logística com ADASYN\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zv-K_RXqfz4o"
   },
   "source": [
    "Comparação Curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7Fwna0bif3nB",
    "outputId": "38806156-a267-47f2-d8e2-7a0c0c043ae7"
   },
   "outputs": [],
   "source": [
    "# Curvas ROC para todos os modelos\n",
    "fpr_orig, tpr_orig, _ = roc_curve(y_test, y_proba)\n",
    "fpr_smote, tpr_smote, _ = roc_curve(y_test, y_proba_smote)\n",
    "fpr_adasyn, tpr_adasyn, _ = roc_curve(y_test, y_proba_adasyn)\n",
    "\n",
    "auc_orig = auc(fpr_orig, tpr_orig)\n",
    "auc_smote = auc(fpr_smote, tpr_smote)\n",
    "auc_adasyn = auc(fpr_adasyn, tpr_adasyn)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr_orig, tpr_orig, label=f\"Original (AUC = {auc_orig:.2f})\", lw=2)\n",
    "plt.plot(fpr_smote, tpr_smote, label=f\"SMOTE    (AUC = {auc_smote:.2f})\", lw=2)\n",
    "plt.plot(fpr_adasyn, tpr_adasyn, label=f\"ADASYN   (AUC = {auc_adasyn:.2f})\", lw=2)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\", label=\"Aleatório\")\n",
    "\n",
    "plt.xlabel(\"Taxa de Falsos Positivos (FPR)\")\n",
    "plt.ylabel(\"Taxa de Verdadeiros Positivos (TPR)\")\n",
    "plt.title(\"Curva ROC - Comparação: Original, SMOTE e ADASYN\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Comparação de F1-score e Recall para limiar 0.5\n",
    "y_pred_orig = (y_proba >= 0.5).astype(int)\n",
    "y_pred_smote = (y_proba_smote >= 0.5).astype(int)\n",
    "y_pred_adasyn = (y_proba_adasyn >= 0.5).astype(int)\n",
    "\n",
    "f1_orig = f1_score(y_test, y_pred_orig)\n",
    "f1_smote = f1_score(y_test, y_pred_smote)\n",
    "f1_adasyn = f1_score(y_test, y_pred_adasyn)\n",
    "\n",
    "recall_orig = recall_score(y_test, y_pred_orig)\n",
    "recall_smote = recall_score(y_test, y_pred_smote)\n",
    "recall_adasyn = recall_score(y_test, y_pred_adasyn)\n",
    "\n",
    "print(\"\\nComparação de F1-score e Recall:\")\n",
    "print(f\"Original  → F1: {f1_orig:.2f} | Recall: {recall_orig:.2f}\")\n",
    "print(f\"SMOTE     → F1: {f1_smote:.2f} | Recall: {recall_smote:.2f}\")\n",
    "print(f\"ADASYN    → F1: {f1_adasyn:.2f} | Recall: {recall_adasyn:.2f}\")\n",
    "\n",
    "# Gráfico comparativo de F1-score e Recall\n",
    "labels = [\"Original\", \"SMOTE\", \"ADASYN\"]\n",
    "f1_scores = [f1_orig, f1_smote, f1_adasyn]\n",
    "recalls = [recall_orig, recall_smote, recall_adasyn]\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "width = 0.35\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(x - width / 2, f1_scores, width, label=\"F1-Score\")\n",
    "plt.bar(x + width / 2, recalls, width, label=\"Recall\")\n",
    "plt.xticks(x, labels)\n",
    "plt.ylabel(\"Valor\")\n",
    "plt.title(\"Comparação de F1-Score e Recall\")\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
